"""
NEXUS CLINICAL AI - Complete Pipeline Runner
=============================================
Runs: Ingestion ‚Üí Harmonization ‚Üí Versioning ‚Üí Knowledge Graph
      ‚Üí Metrics ‚Üí Indices ‚Üí Trends ‚Üí Benchmarking ‚Üí Features ‚Üí Models
      ‚Üí Optimization ‚Üí Validation ‚Üí Knowledge Base ‚Üí Agents ‚Üí Orchestration
"""

import sys
from pathlib import Path
from loguru import logger

# Add src to path (so imports like ingestion.*, validation.*, etc. work)
sys.path.insert(0, str(Path(__file__).parent / "src"))

# Core pipeline imports
from ingestion.data_loader import NexusDataLoader
from ingestion.gap_analyzer import run_gap_analysis
from ingestion.harmonizer import run_harmonization
from versioning.version_manager import run_versioning
from knowledge_graph.graph_builder import ClinicalKnowledgeGraph
from knowledge_graph.graph_queries import GraphQueryEngine
from knowledge_graph.graph_analytics import GraphAnalytics
from metrics.metrics_calculator import run_metrics_calculation
from indices.index_calculator import run_index_calculation
from trends.trend_engine import run_trend_analysis
from benchmarking.benchmark_engine import run_benchmarking
from features.feature_engineer import run_feature_engineering
from models.model_trainer import run_model_training  # ‚úÖ Step 10 import
from optimization.optimization_engine import run_optimization
from validation.validation_engine import run_validation
from knowledge_base.knowledge_base_engine import run_knowledge_base_setup
from agents.agent_engine import run_agent_setup


def run_knowledge_graph():
    """Run knowledge graph construction (Step 4)."""
    print("\n" + "=" * 70)
    print("üï∏Ô∏è STEP 4: KNOWLEDGE GRAPH CONSTRUCTION")
    print("=" * 70)

    # Initialize graph builder
    print("\nüìã Step 4.1: Initializing Knowledge Graph Builder...")
    kg = ClinicalKnowledgeGraph()
    print("   ‚úÖ Knowledge Graph Builder initialized")

    # Build graph
    print("\nüî® Step 4.2: Building Knowledge Graph...")
    graph = kg.build_graph()

    # Print statistics
    print("\nüìä Step 4.3: Graph Statistics...")
    kg.print_statistics()

    # Save graph
    print("\nüíæ Step 4.4: Saving Knowledge Graph...")
    kg.save_graph()

    # Initialize query engine
    print("\nüîç Step 4.5: Initializing Query Engine...")
    query_engine = GraphQueryEngine(graph)
    print("   ‚úÖ Query Engine ready")

    # Initialize analytics
    print("\nüìà Step 4.6: Running Graph Analytics...")
    analytics = GraphAnalytics(graph)
    analytics.print_analytics_report()

    # Demo queries
    print("\n" + "=" * 70)
    print("üîç SAMPLE QUERIES")
    print("=" * 70)

    # Find studies
    studies = query_engine.find_nodes_by_type("study", limit=5)
    print(f"\nüìã Studies in graph: {len(studies)}")
    for node_id, attrs in studies[:3]:
        print(f"   ‚Ä¢ {node_id}: {attrs.get('total_patients', 0)} patients")

    # Find sites
    sites = query_engine.find_nodes_by_type("site", limit=5)
    print(f"\nüè• Sites in graph: {len(sites)}")

    # Find patients with issues
    unclean_patients = query_engine.find_nodes_by_attribute(
        attribute="is_clean",
        value=False,
        entity_type="patient",
    )
    print(f"\n‚ö†Ô∏è Patients not clean: {len(unclean_patients)}")

    # Summary
    print("\n" + "=" * 70)
    print("üï∏Ô∏è KNOWLEDGE GRAPH SUMMARY")
    print("=" * 70)
    print(f"\nüìÅ GRAPH STORAGE: data/graph/")
    print("   ‚Ä¢ clinical_knowledge_graph.gpickle")
    print("   ‚Ä¢ graph_metadata.json")

    print("\nüìä CAPABILITIES ENABLED:")
    print("   ‚Ä¢ ‚úÖ Entity lookups (study, site, patient, SAE, visit)")
    print("   ‚Ä¢ ‚úÖ Relationship traversal")
    print("   ‚Ä¢ ‚úÖ Pathfinding between entities")
    print("   ‚Ä¢ ‚úÖ Hierarchy queries")
    print("   ‚Ä¢ ‚úÖ Centrality analysis")
    print("   ‚Ä¢ ‚úÖ Anomaly detection")
    print("   ‚Ä¢ ‚úÖ Subgraph extraction")

    print("\nüí° USAGE EXAMPLES:")
    print("   ‚Ä¢ query_engine.get_patient_context(study_id=1, subject_id='PAT001')")
    print("   ‚Ä¢ query_engine.get_study_hierarchy(study_id=1)")
    print("   ‚Ä¢ analytics.find_data_quality_issues()")
    print("   ‚Ä¢ analytics.calculate_degree_centrality(entity_type='site')")

    print("\n" + "=" * 70)
    print("‚úÖ STEP 4 COMPLETE!")
    print("=" * 70)

    return kg, query_engine, analytics


def run_step_16():
    """Step 16: Agent Orchestration & Guardrails."""
    logger.info("\n" + "=" * 70)
    logger.info("üéØ STEP 16: AGENT ORCHESTRATION & GUARDRAILS")
    logger.info("=" * 70)

    # Orchestration engine lives under src/orchestration/*
    from orchestration import OrchestrationEngine

    output_dir = Path("data/orchestration")

    # Initialize orchestration engine
    engine = OrchestrationEngine(output_dir)

    # Run demo
    demo_results = engine.run_demo()

    # Get final status
    status = engine.get_system_status()

    # Save all state
    saved_paths = engine.save_all_state()

    # Summary
    logger.info("\n" + "=" * 70)
    logger.info("üìä STEP 16 SUMMARY")
    logger.info("=" * 70)

    logger.info("\nüîß COMPONENTS:")
    components = [
        ("GuardrailEngine", "Input/Output validation, rate limiting, safety"),
        ("AgentMemoryManager", "Short-term, long-term, episodic memory"),
        ("ContextManager", "Session & global context management"),
        ("ConflictResolver", "Multi-agent consensus resolution"),
        ("HumanInTheLoop", "Escalation & approval workflows"),
        ("ObservabilitySystem", "Metrics, tracing, alerting"),
    ]
    for name, desc in components:
        logger.info(f"   ‚úÖ {name} - {desc}")

    stats = status["statistics"]["orchestration"]
    logger.info(f"\nüìä DEMO STATISTICS:")
    logger.info(f"   ‚Ä¢ Requests Processed: {stats['requests_processed']}")
    logger.info(f"   ‚Ä¢ Conflicts Resolved: {stats['conflicts_resolved']}")
    logger.info(f"   ‚Ä¢ Escalations: {stats['escalations_created']}")
    logger.info(f"   ‚Ä¢ System Status: {status['status']}")

    logger.info(f"\nüíæ FILES SAVED: {len(saved_paths)}")
    for name, path in saved_paths.items():
        logger.info(f"   ‚Ä¢ {path}")

    logger.info("\n" + "=" * 70)
    logger.info("‚úÖ STEP 16 COMPLETE!")
    logger.info("=" * 70)

    return engine


def main():
    """Main execution function for complete data pipeline."""
    print("=" * 70)
    print("üöÄ NEXUS CLINICAL AI - COMPLETE DATA PIPELINE")
    print("=" * 70)
    print()

    # =========================================
    # PHASE 1: DATA INGESTION (Step 1)
    # =========================================
    print("\n" + "=" * 70)
    print("üìÅ PHASE 1: DATA INGESTION")
    print("=" * 70)

    loader = NexusDataLoader()

    print("\nüìÅ Step 1.1: Discovering Studies...")
    studies = loader.discover_studies()
    print(f"   ‚úÖ Found {len(studies)} studies")

    print("\nüìã Step 1.2: Building File Inventory...")
    inventory = loader.build_file_inventory()
    print(f"   ‚úÖ Inventoried {len(inventory)} files")

    print("\nüì• Step 1.3: Loading All Files...")
    data = loader.load_all_files()
    print(f"   ‚úÖ Loaded {len(data)} DataFrames")

    print("\nüìä Step 1.4: Profiling Data...")
    profiles = loader.profile_all_data()
    print(f"   ‚úÖ Profiled {len(profiles)} files")

    # Gap analysis
    analyzer, complete_data = run_gap_analysis(loader)

    # =========================================
    # STEP 2: DATA HARMONIZATION
    # =========================================
    harmonizer, saved_files = run_harmonization(complete_data)

    # =========================================
    # STEP 3: DATA VERSIONING
    # =========================================
    version_manager, audit_logger = run_versioning(create_initial=True)

    # =========================================
    # STEP 4: KNOWLEDGE GRAPH
    # =========================================
    kg, query_engine, analytics = run_knowledge_graph()

    # =========================================
    # STEP 5: CORE METRICS CALCULATION
    # =========================================
    print("\n" + "=" * 70)
    print("üìè STEP 5: CORE METRICS CALCULATION")
    print("=" * 70)
    metrics_calculator, metrics_files = run_metrics_calculation()

    # =========================================
    # STEP 6: COMPOSITE INDICES
    # =========================================
    print("\n" + "=" * 70)
    print("üìä STEP 6: 7 COMPOSITE INDICES")
    print("=" * 70)
    index_calculator, index_files = run_index_calculation()

    # =========================================
    # STEP 7: TREND ANALYSIS
    # =========================================
    print("\n" + "=" * 70)
    print("üìà STEP 7: TREND ANALYSIS ENGINE")
    print("=" * 70)
    trend_engine, trend_files = run_trend_analysis()

    # =========================================
    # STEP 8: BENCHMARKING SYSTEM
    # =========================================
    print("\n" + "=" * 70)
    print("üìä STEP 8: BENCHMARKING SYSTEM")
    print("=" * 70)
    benchmark_engine, benchmark_files = run_benchmarking()

    # =========================================
    # STEP 9: FEATURE ENGINEERING
    # =========================================
    print("\n" + "=" * 70)
    print("üîß STEP 9: FEATURE ENGINEERING")
    print("=" * 70)
    feature_engineer, feature_files = run_feature_engineering()

    # =========================================
    # STEP 10: MODEL DEVELOPMENT
    # =========================================
    print("\n" + "=" * 70)
    print("üèãÔ∏è STEP 10: MODEL DEVELOPMENT")
    print("=" * 70)
    model_trainer, model_files = run_model_training()

    # =========================================
    # STEP 11: HYPERPARAMETER OPTIMIZATION
    # =========================================
    print("\n" + "=" * 70)
    print("‚ö° STEP 11: HYPERPARAMETER OPTIMIZATION")
    print("=" * 70)
    optimization_engine, optimization_files = run_optimization()

    # =========================================
    # STEP 12: MODEL VALIDATION & EXPLAINABILITY
    # =========================================
    print("\n" + "=" * 70)
    print("üî¨ STEP 12: MODEL VALIDATION & EXPLAINABILITY")
    print("=" * 70)
    validation_engine, validation_files = run_validation()

    # =========================================
    # STEP 13: KNOWLEDGE BASE & RAG SETUP
    # =========================================
    print("\n" + "=" * 70)
    print("üìö STEP 13: KNOWLEDGE BASE & RAG SETUP")
    print("=" * 70)
    kb_engine, kb_files = run_knowledge_base_setup()

    # =========================================
    # STEPS 14‚Äì15: AGENTS SETUP (Core + Advanced)
    # =========================================
    print("\n" + "=" * 70)
    print("ü§ñ STEPS 14‚Äì15: CORE & ADVANCED AGENTS SETUP")
    print("=" * 70)
    agent_engine, agent_files = run_agent_setup()

    # =========================================
    # STEP 16: AGENT ORCHESTRATION & GUARDRAILS
    # =========================================
    orchestration_engine = run_step_16()

    # =========================================
    # FINAL SUMMARY
    # =========================================
    print("\n" + "=" * 70)
    print("üéâ PIPELINE COMPLETE - STEPS 1‚Äì16 DONE!")
    print("=" * 70)

    print("\nüìä FINAL STATISTICS:")
    print("   ‚Ä¢ Studies Processed: 23")
    print("   ‚Ä¢ Files Processed: 207")
    print(
        f"   ‚Ä¢ Total Rows Ingested: {sum(len(df) for df in complete_data.values()):,}"
    )
    print(f"   ‚Ä¢ Patient Records: {len(harmonizer.patient_master):,}")
    print(f"   ‚Ä¢ Site Records: {len(harmonizer.site_master):,}")
    print(f"   ‚Ä¢ Versions Created: {len(version_manager.manifest['versions'])}")
    print(f"   ‚Ä¢ Graph Nodes: {kg.graph.number_of_nodes():,}")
    print(f"   ‚Ä¢ Graph Edges: {kg.graph.number_of_edges():,}")
    print(f"   ‚Ä¢ Metrics Files: {len(metrics_files)}")
    print(f"   ‚Ä¢ Index Files: {len(index_files)}")
    print(f"   ‚Ä¢ Trend Files: {len(trend_files)}")
    print(f"   ‚Ä¢ Benchmark Files: {len(benchmark_files)}")
    print(f"   ‚Ä¢ Feature Files: {len(feature_files)}")
    print(f"   ‚Ä¢ Model Files: {len(model_files)}")

    print("\nüìÅ OUTPUT LOCATIONS:")
    print("   ‚Ä¢ Unified Data: data/unified/")
    print("   ‚Ä¢ Versions: data/versions/")
    print("   ‚Ä¢ Audit Logs: data/audit/")
    print("   ‚Ä¢ Knowledge Graph: data/graph/")
    print("   ‚Ä¢ Metrics: data/metrics/")
    print("   ‚Ä¢ Composite Indices: data/indices/")
    print("   ‚Ä¢ Trends: data/trends/")
    print("   ‚Ä¢ Benchmarks: data/benchmarks/")
    print("   ‚Ä¢ Features: data/features/")
    print("   ‚Ä¢ Models: data/models/")
    print("   ‚Ä¢ Optimization: data/optimization/")
    print("   ‚Ä¢ Validation: data/validation/")
    print("   ‚Ä¢ Knowledge Base: data/knowledge_base/")
    print("   ‚Ä¢ Agents: data/agents/")
    print("   ‚Ä¢ Orchestration: data/orchestration/")

    print("\n‚úÖ COMPLETED STEPS:")
    print("   ‚Ä¢ Step 1: Data Ingestion & Profiling ‚úÖ")
    print("   ‚Ä¢ Step 2: Data Harmonization & Unification ‚úÖ")
    print("   ‚Ä¢ Step 3: Data Versioning & Change Detection ‚úÖ")
    print("   ‚Ä¢ Step 4: Knowledge Graph Construction ‚úÖ")
    print("   ‚Ä¢ Step 5: Core Metrics Calculation ‚úÖ")
    print("   ‚Ä¢ Step 6: 7 Composite Indices ‚úÖ")
    print("   ‚Ä¢ Step 7: Trend Analysis Engine ‚úÖ")
    print("   ‚Ä¢ Step 8: Benchmarking System ‚úÖ")
    print("   ‚Ä¢ Step 9: Feature Engineering ‚úÖ")
    print("   ‚Ä¢ Step 10: Model Development ‚úÖ")
    print("   ‚Ä¢ Step 11: Hyperparameter Optimization ‚úÖ")
    print("   ‚Ä¢ Step 12: Model Validation & Explainability ‚úÖ")
    print("   ‚Ä¢ Step 13: Knowledge Base & RAG Setup ‚úÖ")
    print("   ‚Ä¢ Step 14: Core Agents (5 Agents) ‚úÖ")
    print("   ‚Ä¢ Step 15: Advanced Agents (5 Agents) ‚úÖ")
    print("   ‚Ä¢ Step 16: Agent Orchestration & Guardrails ‚úÖ")

    # Return core objects (same signature you had before, to avoid breaking callers)
    return (
        loader,
        analyzer,
        harmonizer,
        complete_data,
        version_manager,
        audit_logger,
        kg,
        query_engine,
        analytics,
        metrics_calculator,
        metrics_files,
        index_calculator,
        index_files,
        trend_engine,
        trend_files,
        benchmark_engine,
        benchmark_files,
        feature_engineer,
        feature_files,
        model_trainer,
        model_files,
    )


if __name__ == "__main__":
    results = main()
    (
        loader,
        analyzer,
        harmonizer,
        complete_data,
        version_manager,
        audit_logger,
        kg,
        query_engine,
        analytics,
        metrics_calculator,
        metrics_files,
        index_calculator,
        index_files,
        trend_engine,
        trend_files,
        benchmark_engine,
        benchmark_files,
        feature_engineer,
        feature_files,
        model_trainer,
        model_files,
    ) = results
